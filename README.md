# ğŸ¤Ÿ Sign Language Alphabet Translator (Aâ€“Z) â€“ Real-Time

A simple real-time Sign Language Alphabet Recognition system using Python, OpenCV, and MediaPipe.  
It captures hand landmarks via webcam and predicts **Aâ€“Z letters only** using a trained machine learning model (Random Forest).

## ğŸ’¡ Features

- ğŸ–ï¸ Hand tracking using MediaPipe
- ğŸ“· Real-time webcam support
- ğŸ“Š Train your own dataset (Aâ€“Z signs)
- ğŸ§  ML model trained on landmarks
- ğŸ’¾ Data saved as CSV, model saved as .pkl


## ğŸ§‘â€ğŸ’» Tech Stack

- Python 3.10+
- OpenCV
- MediaPipe
- Scikit-learn
- Pandas
- NumPy


## ğŸ› ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/your-username/SignLanguageTranslator.git
cd SignLanguageTranslator


SignLanguageTranslator/
â”œâ”€â”€ collect_data.py           # Collect sign data (Aâ€“Z)
â”œâ”€â”€ train_model.py            # Train Random Forest model
â”œâ”€â”€ predict.py                # Real-time sign prediction
â”œâ”€â”€ webcam_test.py            # Test webcam and hand tracking
â”œâ”€â”€ hand_landmark_test.py     # Display hand landmarks
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sign_data.csv         # Dataset generated from webcam
â”œâ”€â”€ sign_model.pkl            # Trained model (output)
â”œâ”€â”€ requirements.txt          # Python dependencies
â””â”€â”€ README.md                 # This file

